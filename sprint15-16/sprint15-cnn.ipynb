{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint15　CNN\n",
    "### スクラッチでCNN (LeNet)を実装し、CIFER10画像認識タスクに適用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 36s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "from keras.datasets import cifar10\n",
    "image_num = 25000\n",
    "\n",
    "(x_train_cifar10, y_train_cifar10), (x_test_cifar10, y_test_cifar10) = cifar10.load_data()\n",
    "\n",
    "x_train_cifar10 = x_train_cifar10[:image_num]\n",
    "y_train_cifar10 = y_train_cifar10[:image_num]\n",
    "y_label_cifar10 = y_train_cifar10\n",
    "y_train_cifar10 = np.identity(10)[y_train_cifar10]\n",
    "del x_test_cifar10, y_test_cifar10\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 32, 32, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cifar10.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### im2col col2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(x, filter_size=4, stride=4, pad=0, padding='constant'):\n",
    "    if pad > 0:\n",
    "        x = np.pad(x, [(0, 0), (pad, pad), (pad, pad), (0, 0)], padding)\n",
    "    N, H, W, C = x.shape\n",
    "    return np.array([x[n, h:h + filter_size, w:w + filter_size, c].flatten() \\\n",
    "                     for c in range(C) \\\n",
    "                     for n in range(N) \\\n",
    "                     for h in range(0, H - filter_size + 1, stride) \\\n",
    "                     for w in range(0, W - filter_size + 1, stride)])\n",
    "\n",
    "\n",
    "def im2col_v2(x, filter_size=4, stride=4, pad=0, padding='constant'):\n",
    "    if pad > 0:\n",
    "        x = np.pad(x, [(0, 0), (pad, pad), (pad, pad), (0, 0)], padding)\n",
    "    data_size, height, width, channel = x.shape\n",
    "    return np.array([x[n, h:h + filter_size, w:w + filter_size, :].flatten() \\\n",
    "                     for n in range(data_size) \\\n",
    "                     for h in range(0, height - filter_size + 1, stride) \\\n",
    "                     for w in range(0, width - filter_size + 1, stride)])\n",
    "\n",
    "\n",
    "def im2col_v3(x, filter_size=4, stride=4, pad=0, padding='constant'):\n",
    "    if pad > 0:\n",
    "        x = np.pad(x, [(0, 0), (pad, pad), (pad, pad), (0, 0)], padding)\n",
    "    data_size, height, width, channel = x.shape\n",
    "    return np.array([x[:, h:h + filter_size, w:w + filter_size, c].flatten() \\\n",
    "                     for c in range(channel) \\\n",
    "                     for h in range(0, height - filter_size + 1, stride) \\\n",
    "                     for w in range(0, width - filter_size + 1, stride)])\n",
    "\n",
    "\n",
    "def col2im_v2(x, input_shape, filter_size=4, stride=4, pad=0, padding='constant'):\n",
    "    #_, out_H, out_W, _ = x.shape\n",
    "    in_N, in_H, in_W, in_C = input_shape\n",
    "    out_H = 1 + int((in_H + 2 * pad - filter_size) / stride)\n",
    "    out_W = 1 + int((in_W + 2 * pad - filter_size) / stride)\n",
    "    img = np.zeros((in_N, in_H + 2*pad, in_W + 2*pad, in_C))\n",
    "    for i, line in enumerate(x):\n",
    "        data_i, square_i = divmod(i, out_H*out_W)\n",
    "        height_i, width_i = divmod(square_i, out_H)\n",
    "        img[data_i, height_i: height_i+filter_size, width_i:width_i + filter_size, :] =\\\n",
    "        line.reshape(filter_size, filter_size, in_C)\n",
    "    return img[:, pad:pad + in_H, pad:pad + in_W, :]\n",
    "\n",
    "\n",
    "def col2im_v3(x, input_shape, filter_size=4, stride=4, pad=0, padding='constant'):\n",
    "    #_, out_H, out_W, _ = x.shape\n",
    "    in_N, in_H, in_W, in_C = input_shape\n",
    "    out_H = 1 + int((in_H + 2 * pad - filter_size) / stride)\n",
    "    out_W = 1 + int((in_W + 2 * pad - filter_size) / stride)\n",
    "    img = np.zeros((in_N, in_H + 2*pad, in_W + 2*pad, in_C))\n",
    "    for i, line in enumerate(x):\n",
    "        channel_i, data_i = divmod(i, in_N*out_H* out_W)\n",
    "        data_i, square_i = divmod(data_i, out_H*out_W)\n",
    "        height_i, width_i = divmod(square_i, out_H)\n",
    "        height_i *= stride\n",
    "        width_i *= stride\n",
    "        img[data_i, height_i: height_i+filter_size, width_i:width_i + filter_size, channel_i] =\\\n",
    "        line.reshape(filter_size, filter_size)\n",
    "    return img[:, pad:pad + in_H, pad:pad + in_W, :]\n",
    "\n",
    "\n",
    "def col2im(x, input_shape, filter_size=4, stride=4, pad=0, padding='constant'):\n",
    "    # 戻すデータの形状\n",
    "    N, H, W, C = input_shape\n",
    "    img = np.zeros((N, H + 2*pad, W + 2*pad, C))\n",
    "    block_num = (pad * 2 + W - filter_size) // stride + 1  \n",
    "    # １チャネルに何行あるか\n",
    "    c_vol = int(x.shape[0] / C)\n",
    "    n_vol = int(c_vol / N)\n",
    "\n",
    "    for i, line in enumerate(x):\n",
    "        block = line.reshape(filter_size, filter_size)\n",
    "        channel_i = i // c_vol\n",
    "        data_i = i % c_vol // n_vol\n",
    "        start_h, start_w = divmod(i % n_vol, block_num)\n",
    "        start_h, start_w = int(start_h), int(start_w)\n",
    "        end_h = start_h + filter_size\n",
    "        end_w = start_w + filter_size\n",
    "\n",
    "        try:\n",
    "            img[data_i, start_h:end_h, start_w:end_w, channel_i] = block\n",
    "        except:\n",
    "            print(\"N {} H {} W {} C {} \".format(data_i, start_h, start_w, channel_i))\n",
    "            print(block.shape)\n",
    "            print(\"img shape {}\".format(img.shape))\n",
    "            print(img[data_i, start_h:end_h, start_w:end_w, channel_i].shape)\n",
    "            print('i {} c_vol {} n_vol {} block_num {}'.format(i, c_vol, n_vol, block_num))\n",
    "            raise\n",
    "\n",
    "    return img[:, pad:pad + H, pad:pad + W, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単層クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, params={}):\n",
    "        if 'input_shape' in params:\n",
    "            self.in_shape = params['input_shape']\n",
    "        else:\n",
    "            self.in_shape = None\n",
    "\n",
    "        if 'output_shape' in params:\n",
    "            self.out_shape = params['output_shape']\n",
    "        else:\n",
    "            self.out_shape = None\n",
    "\n",
    "            \n",
    "class MaxPooling(Layer):\n",
    "    def __init__(self, pool_size=4, stride=-1, pad=0, params={}):\n",
    "        super(MaxPooling, self).__init__(params)\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.stride = self.pool_size if self.stride == -1 else stride\n",
    "        self.max_index = None\n",
    "        self.input_shape = None \n",
    "\n",
    "        \n",
    "    def initialize(self, in_shape, params={}):\n",
    "        self.in_shape = in_shape\n",
    "        N, H, W, C = in_shape\n",
    "        out_h = 1 + int((H + 2 * self.pad - self.pool_size) / self.stride)\n",
    "        out_w = 1 + int((W + 2 * self.pad - self.pool_size) / self.stride)\n",
    "        self.out_shape = (N, out_h, out_w, C)\n",
    "        print(\"Pooling : out {} filter {} stride {} pad {} \".format(self.out_shape, \\\n",
    "                                                                    self.pool_size, \\\n",
    "                                                                    self.stride,\\\n",
    "                                                                    self.pad))\n",
    "        return self.out_shape\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.input_shape = x.shape\n",
    "        N, H, W, C = x.shape\n",
    "        out_h = 1 + int((H + 2 * self.pad - self.pool_size) / self.stride)\n",
    "        out_w = 1 + int((W + 2 * self.pad - self.pool_size) / self.stride)\n",
    "        col = im2col(x, self.pool_size, self.stride, self.pad)\n",
    "        col_max = np.max(col, axis=1)\n",
    "        self.max_index = np.argmax(col, axis=1)\n",
    "        return col_max.reshape(C, N, out_h, out_w).transpose(1, 2, 3, 0)\n",
    "\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        filter_size = dout.shape[1]\n",
    "        N, out_h, out_w, _ = self.out_shape\n",
    "        dout_line = dout.transpose(3, 0, 1, 2).reshape(-1)\n",
    "        dout = np.zeros([dout_line.shape[0], self.pool_size * self.pool_size])\n",
    "        for i, max_i in enumerate(self.max_index):\n",
    "            dout[i, max_i] = dout_line[i]\n",
    "        return col2im_v3(dout, self.input_shape, self.pool_size, self.stride, self.pad)\n",
    "\n",
    "\n",
    "class Convolution(Layer):\n",
    "    def __init__(self, out_channel=1, filter_size=3, stride=1, pad=0, bias=True, params={}):\n",
    "        #self.out_channel = out_channel\n",
    "        self.filnum = out_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.filter_size = filter_size\n",
    "        self.filsize = filter_size\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.bias = bias\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        self.x = None\n",
    "        self.padding = 'constant'\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        self.optimize = None\n",
    "        if 'lr' in params:\n",
    "            self.lr = params['lr']\n",
    "        else:\n",
    "            self.lr = 0.01\n",
    "        self.x_2dim = None\n",
    "\n",
    "        \n",
    "    def initialize(self, in_shape, params={}):\n",
    "        self.in_shape = in_shape  \n",
    "        N, H, W, in_channel = in_shape\n",
    "        out_h = 1 + int((H + 2 * self.pad - self.filter_size) / self.stride)\n",
    "        out_w = 1 + int((W + 2 * self.pad - self.filter_size) / self.stride)\n",
    "        self.out_shape = (N, out_h, out_w, self.out_channel)\n",
    "        # 重みの初期化\n",
    "        ww = np.random.randn(self.filter_size * self.filter_size * in_channel, self.out_channel)\n",
    "        self.W2 = ww * 0.01\n",
    "        self.W = ww.reshape(self.filnum, self.filsize, self.filsize, in_channel,order='F').transpose(0,2,1,3)\n",
    "        self.b = np.random.randn(1, self.filnum)\n",
    "        self.db = np.zeros((1, self.filnum))\n",
    "        \n",
    "        if 'optimizer' in params:\n",
    "            if params['optimizer'] == 'sgd':\n",
    "                self.optimize = self.update_sgd\n",
    "            elif params['optimizer'] == 'adagrad':\n",
    "                self.h = np.zeros_like(W)\n",
    "                self.optimize = self.update_adagrad\n",
    "            else:  # params['optimizer'] == 'adam':\n",
    "                self.m = np.zeros_like(self.W)\n",
    "                self.v = np.zeros_like(self.W)\n",
    "                self.beta1 = 0.9\n",
    "                self.beta2 = 0.999\n",
    "                self.optimize = self.update_adam\n",
    "        else:\n",
    "            self.optimize = self.update_sgd\n",
    "            \n",
    "        print(\"Convolution : out {}, filter {}, stride {} \".format(self.out_shape, self.filter_size,\\\n",
    "                                                                   self.stride))\n",
    "        \n",
    "        return self.out_shape\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.pad > 0:\n",
    "            x1 = np.pad(x, [(0, 0), (self.pad, self.pad), (self.pad, self.pad), (0, 0)], self.padding)\n",
    "        self.x = x1\n",
    "        v_num = 1 + ((self.x.shape[1] - self.filsize) // self.stride)\n",
    "        h_num = 1 + ((self.x.shape[2] - self.filsize) // self.stride) \n",
    "        self.h_num = h_num    \n",
    "        W_matrix = np.zeros((self.W.shape[0], self.W.shape[1] * self.W.shape[2] * self.W.shape[3]))\n",
    "        X_matrix = np.zeros((self.W.shape[1] * self.W.shape[2] * self.W.shape[3],\\\n",
    "                             v_num * h_num * self.x.shape[0]))\n",
    "        for c in range(self.W.shape[3]):\n",
    "            filtersize = self.W.shape[1] * self.W.shape[2]\n",
    "            head = c * filtersize\n",
    "            bottom = head + filtersize\n",
    "            for f in range(self.W.shape[0]):          \n",
    "                W_matrix[f,head:bottom] = self.W[f, :, :, c].reshape(1,-1)\n",
    "            for p in range(self.x.shape[0]):\n",
    "                col = p * v_num * h_num\n",
    "                start = c * filtersize\n",
    "                end = start + filtersize\n",
    "                for v in range(v_num):\n",
    "                    v1 = v * self.stride\n",
    "                    v2 = v1 + self.filsize\n",
    "                    for h in range(h_num):\n",
    "                        h1 = h * self.stride \n",
    "                        h2 = h1 + self.filsize \n",
    "                        X_matrix[start:end,col:col+1] = self.x[p, v1:v2, h1:h2, c].reshape(-1,1)\n",
    "                        col +=1         \n",
    "        channel_result = np.dot(W_matrix, X_matrix) + self.b.T\n",
    "        channel_result = channel_result.transpose(1,0).reshape(self.x.shape[0], h_num, v_num, self.filnum)\n",
    "        self.X_matrix = X_matrix      \n",
    "        N, _, _, _ = x.shape\n",
    "        _, out_h, out_w, _ = self.out_shape\n",
    "        x_2dim = im2col_v2(x, self.filter_size, self.stride, self.pad)\n",
    "        out = np.dot(x_2dim, self.W2) + self.b\n",
    "        # 整形する　out_C, W * H *N -> N H W out_C\n",
    "        out = out.reshape(N, out_h, out_w, -1)\n",
    "        self.x_2dim = x_2dim    \n",
    "        return channel_result \n",
    "\n",
    "\n",
    "    def backward(self, dout):\n",
    "        Wmatrix = np.zeros((self.filnum * dout.shape[1]**2, self.x.shape[3] * self.x.shape[1]**2))\n",
    "        dout_size = dout.shape[1]*dout.shape[2]\n",
    "        for c in range(self.x.shape[3]):\n",
    "            for f in range(self.filnum):\n",
    "                gap = self.x.shape[1] - self.filsize\n",
    "                content = np.zeros((1, self.filsize**2 + gap * (self.filsize-1)))\n",
    "                for i in range(self.filsize):\n",
    "                    start = i * (self.filsize + gap)\n",
    "                    content[0, start:start+self.filsize] = self.W[f,i,:,c]   \n",
    "                head = c * self.x.shape[1]**2\n",
    "                for row in range(dout_size):\n",
    "                    head += self.stride\n",
    "                    if (row % self.h_num) == 0:\n",
    "                        head = self.x.shape[1] * self.stride * (row // self.h_num) + c * self.x.shape[1]**2\n",
    "                    Wmatrix[f*dout_size+row, head:head+content.shape[1]] = content\n",
    "                     \n",
    "        dout2 = dout.transpose(0,3,1,2).reshape(self.x.shape[0], self.filnum * dout.shape[1]**2) \n",
    "        dx0 = np.dot(dout2, Wmatrix)  \n",
    "        dx = dx0.reshape(self.x.shape[0], self.x.shape[1], self.x.shape[2], self.x.shape[3],order='F')\\\n",
    "             .transpose(0,2,1,3)\n",
    "        dout2 = dout.reshape(dout.shape[0] * dout.shape[1] * dout.shape[2], self.filnum)\n",
    "        dW = np.dot(self.X_matrix, dout2)\n",
    "        self.dW = dW.transpose(1,0).reshape(self.filnum, self.filsize, self.filsize, self.x.shape[3])\n",
    "        for f in range(self.filnum):\n",
    "            self.db[0,f] = np.sum(dout[:,:,:,f])   \n",
    "        dout99 = dout.reshape(-1, self.out_channel)\n",
    "        db99 = np.sum(dout99, axis=0, keepdims=True)\n",
    "        dW99 = np.dot(self.x_2dim.T, dout99)\n",
    "        dx99 = np.dot(dout99, self.W2.T)\n",
    "        dx99 = col2im_v2(dx99, self.in_shape, self.filter_size, self.stride, self.pad)\n",
    "        a111 = dx[:,self.pad:self.pad+self.in_shape[1],self.pad:self.pad+self.in_shape[2],:]\n",
    "        return dx[:,self.pad:self.pad+self.in_shape[1],self.pad:self.pad+self.in_shape[2],:]\n",
    "\n",
    "    \n",
    "    def update_sgd(self):\n",
    "        self.W -= self.lr * self.dW\n",
    "        self.b -= self.lr * self.db\n",
    "\n",
    "    def update_adagrad(self, lr=0.01):\n",
    "        self.h += self.dW ** 2\n",
    "        self.W -= self.lr * self.dW / (np.sqrt(self.h) + 1e-7)\n",
    "        self.b -= self.lr * self.db\n",
    "\n",
    "    def update_adam(self, lr=0.01):\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * self.dW\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * (self.dW * self.dW)\n",
    "        m_hat = self.m / (1 - self.beta1)\n",
    "        v_hat = self.v / (1 - self.beta2)\n",
    "        self.W -= self.lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n",
    "        self.b -= self.lr * self.db\n",
    "\n",
    "\n",
    "class Flatten(Layer):\n",
    "    # (N, H, W, C)　→　(N, H * W * C)　　変換\n",
    "    def __init__(self, params={}):\n",
    "        super(Flatten, self).__init__(params)\n",
    "\n",
    "    def initialize(self, in_shape, params={}):\n",
    "        self.in_shape = in_shape\n",
    "        N, H, W, C = in_shape\n",
    "        self.out_shape = (N, H * W * C)\n",
    "        print(\"Flatten : out {} \".format(self.out_shape))\n",
    "        return self.out_shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input_shape = x.shape\n",
    "        out = np.array([elem.flatten() for elem in x])\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.reshape(self.input_shape)\n",
    "        return dout\n",
    "\n",
    "\n",
    "class Dropout(Layer):\n",
    "    def __init__(self, params):\n",
    "        super(Dropout, self).__init__(params)\n",
    "        if 'dropout_ratio' in params:\n",
    "            self.dropout_ratio = params['dropout_ratio']\n",
    "        else:\n",
    "            self.dropout_ratio = 0.5\n",
    "        self.mask = None\n",
    "\n",
    "    def initialize(self, in_shape, params={}):\n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = self.in_shape\n",
    "        print(\"Dropout : ratio {}  \".format(self.dropout_ratio))\n",
    "        return self.out_shape\n",
    "\n",
    "    def forward(self, x, train_flg=True):\n",
    "        if train_flg:\n",
    "            self.mask = np.random.random_sample(x.shape) > self.dropout_ratio \n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x * (1 - self.dropout_ratio)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask\n",
    "\n",
    "\n",
    "class BatchNorm(Layer):\n",
    "    def __init__(self, params):\n",
    "        super(BatchNorm, self).__init__(params)\n",
    "        self.out = None\n",
    "        self.beta = 0.0\n",
    "        self.gamma = 1.0\n",
    "        self.lr = params['lr']\n",
    "        self.eps = 1e-8\n",
    "\n",
    "\n",
    "    def initialize(self, in_shape, params={}):\n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = self.in_shape\n",
    "        print(\"BatchNorm : out {} lr {}  \".format(self.out_shape, self.lr))\n",
    "        return self.out_shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        # step1: 平均を求める\n",
    "        mu = np.mean(x, axis=0)\n",
    "\n",
    "        # step2: 偏差\n",
    "        self.xmu = x - mu\n",
    "\n",
    "        # step3 : 偏差の２乗\n",
    "        sq = self.xmu ** 2\n",
    "\n",
    "        # step4 : 分散を求める\n",
    "        self.var = np.var(x, axis=0)\n",
    "\n",
    "        # step5 : 分散のルートを取った値を求める\n",
    "        self.sqrtvar = np.sqrt(self.var + self.eps)\n",
    "\n",
    "        # step6 : sqrtvarの逆数（invert）\n",
    "        self.ivar = 1.0 / self.sqrtvar\n",
    "\n",
    "        # step7 : 標準化した値\n",
    "        self.xhat = self.xmu * self.ivar\n",
    "\n",
    "        # step8\n",
    "        gammax = self.gamma * self.xhat\n",
    "\n",
    "        # step9\n",
    "        out = gammax + self.beta\n",
    "\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        N, D = dout.shape\n",
    "        \n",
    "        # step9\n",
    "        self.d_beta = np.sum(dout, axis=0)\n",
    "        dgammax = dout  \n",
    "\n",
    "        # step8\n",
    "        self.d_gamma = np.sum(dgammax * self.xhat, axis=0)\n",
    "        dxhat = dgammax * self.gamma\n",
    "\n",
    "        # step7\n",
    "        divar = np.sum(dxhat * self.xmu, axis=0)\n",
    "        dxmu1 = dxhat * self.ivar\n",
    "\n",
    "        # step6\n",
    "        dsqrtvar = -1. / (self.sqrtvar ** 2) * divar\n",
    "\n",
    "        # step5\n",
    "        dvar = 0.5 * 1. / np.sqrt(self.var + self.eps) * dsqrtvar\n",
    "\n",
    "        # step4\n",
    "        dsq = 1. / N * np.ones((N, D)) * dvar\n",
    "\n",
    "        # step3\n",
    "        dxmu2 = 2 * self.xmu * dsq\n",
    "\n",
    "        # step2\n",
    "        dx1 = (dxmu1 + dxmu2)\n",
    "        dmu = -1 * np.sum(dxmu1 + dxmu2, axis=0)\n",
    "\n",
    "        # step1\n",
    "        dx2 = 1. / N * np.ones((N, D)) * dmu\n",
    "\n",
    "        # step0\n",
    "        dx = dx1 + dx2\n",
    "\n",
    "        return dx\n",
    "\n",
    "    \n",
    "    def optimize(self):\n",
    "        self.gamma -= self.lr * self.d_gamma\n",
    "        self.beta -= self.lr * self.d_beta\n",
    "\n",
    "\n",
    "class Activation(Layer):\n",
    "    def __init__(self, params):\n",
    "        super(Activation, self).__init__(params)\n",
    "        self.out = None\n",
    "        self.mask = None\n",
    "        if 'activation' in params:\n",
    "            if params['activation'] == 'tanh':\n",
    "                self.forward = self.forward_tanh\n",
    "                self.backward = self.backward_tanh\n",
    "            elif params['activation'] == 'sigmoid':\n",
    "                self.forward = self.forward_sigmoid\n",
    "                self.backward = self.backward_sigmoid\n",
    "            else:  # params['activation'] == 'relu':\n",
    "                self.forward = self.forward_relu\n",
    "                self.backward = self.backward_relu\n",
    "        else:\n",
    "            params['activation'] = 'relu'\n",
    "            self.forward = self.forward_relu\n",
    "            self.backward = self.backward_relu\n",
    "\n",
    "    def initialize(self, in_shape, params={}):\n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = self.in_shape\n",
    "        print(\"Activation : out {}   func : {} \".format(self.out_shape, params['activation']))\n",
    "        return self.out_shape\n",
    "\n",
    "    \n",
    "    # ReLu\n",
    "    def forward_relu(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def backward_relu(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        return dx\n",
    "\n",
    "    \n",
    "    # tanh\n",
    "    def forward_tanh(self, x):\n",
    "        out = np.tanh(x)\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def backward_tanh(self, dout):\n",
    "        dx = dout * (1 - np.tanh(dout) ** 2)\n",
    "        return dx\n",
    "\n",
    "    \n",
    "    # sigmoid関数\n",
    "    def forward_sigmoid(self, x):\n",
    "        out = 1 / (1 + np.exp(-x))\n",
    "        self.out = out\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def backward_sigmoid(self, dout):\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Affine(Layer):\n",
    "    def __init__(self, unit_size=100, params={}):\n",
    "        super(Affine, self).__init__(params)\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        self.x = None\n",
    "        self.unit_size = unit_size\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        if 'lr' in params:\n",
    "            self.lr = params['lr']\n",
    "        else:\n",
    "            self.lr = 0.01\n",
    "\n",
    "    def initialize(self, in_shape, params={}):\n",
    "        self.in_shape = in_shape\n",
    "        N, F = in_shape\n",
    "        self.out_shape = (N, self.unit_size)\n",
    "\n",
    "        # 重みの初期化\n",
    "        self.W = np.random.randn(F, self.unit_size)\n",
    "        self.b = np.zeros([1, self.unit_size])\n",
    "        self.W *= 0.01\n",
    "\n",
    "        # オプティマイザの設定\n",
    "        if 'optimizer' in params:\n",
    "            if params['optimizer'] == 'sgd':\n",
    "                self.optimize = self.update_sgd\n",
    "            elif params['optimizer'] == 'adagrad':\n",
    "                self.h = np.zeros_like(self.W)\n",
    "                self.optimize = self.update_adagrad\n",
    "            else:  # params['optimizer'] == 'adam':\n",
    "                self.m = np.zeros_like(self.W)\n",
    "                self.v = np.zeros_like(self.W)\n",
    "                self.beta1 = 0.9\n",
    "                self.beta2 = 0.999\n",
    "                self.optimize = self.update_adam\n",
    "        else:\n",
    "            params['optimizer'] = 'adam'\n",
    "            self.optimize = self.update_adam\n",
    "        print(\"Affine : out {} optimizer {} unit {} \".format(self.out_shape, params['optimizer'],\\\n",
    "                                                             self.unit_size))\n",
    "        return self.out_shape\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        return dx\n",
    "\n",
    "    \n",
    "    def update_sgd(self):\n",
    "        self.W -= self.lr * self.dW\n",
    "        self.b -= self.lr * self.db\n",
    "\n",
    "        \n",
    "    def update_adagrad(self, lr=0.01):\n",
    "        self.h += self.dW ** 2\n",
    "        self.W -= self.lr * self.dW / (np.sqrt(self.h) + 1e-7)\n",
    "        self.b -= self.lr * self.db\n",
    "\n",
    "        \n",
    "    def update_adam(self, lr=0.01):\n",
    "        self.m = self.beta1 * self.m + (1 - self.beta1) * self.dW\n",
    "        self.v = self.beta2 * self.v + (1 - self.beta2) * (self.dW * self.dW)\n",
    "        m_hat = self.m / (1 - self.beta1)\n",
    "        v_hat = self.v / (1 - self.beta2)\n",
    "        self.W -= self.lr * m_hat / (np.sqrt(v_hat) + 1e-8)\n",
    "        self.b -= self.lr * self.db\n",
    "\n",
    "\n",
    "class SoftmaxWithLoss(Layer):\n",
    "    def __init__(self, params={}):\n",
    "        super(SoftmaxWithLoss, self).__init__(params)\n",
    "        self.loss = None  # 損失関数\n",
    "        self.y = None  # softmaxの出力\n",
    "        self.t = None  # 教師データ（one-hot vector)\n",
    "\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size  # delta3に相当\n",
    "        return dx\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def cross_entropy_error(y, y_pred):\n",
    "    data_size = y.shape[0]\n",
    "    cross_entorpy = -np.sum(y * np.log(y_pred + 1e-7))\n",
    "    error = cross_entorpy / data_size\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layersクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class LeNetLayers:\n",
    "    def __init__(self, params):\n",
    "        unit_size_list = [params['input_size']]\n",
    "        unit_size_list.extend(params['hidden_layer_list'])\n",
    "        unit_size_list.append(params['output_size'])\n",
    "\n",
    "        self.params = {}\n",
    "\n",
    "        # レイヤの生成\n",
    "        self.layers = OrderedDict()\n",
    "\n",
    "        self.layers['Conv1'] = Convolution(6, 5, 1, 2)  # 2 (3,3) (1,1) same\n",
    "        self.layers['Active1'] = Activation(params)  # relu\n",
    "        self.layers['Pool1'] = MaxPooling(2, 2, 0, params)\n",
    "        self.layers['Conv2'] = Convolution(16, 5, 1, 2)  # 2 (3,3) (1,1) same\n",
    "        self.layers['Active2'] = Activation(params)  # relu\n",
    "        self.layers['Pool2'] = MaxPooling(2, 2, 0, params)\n",
    "        self.layers['Flatten'] = Flatten(params)\n",
    "        self.layers['Affine1'] = Affine(120, params)\n",
    "        self.layers['BatchNorm1'] = BatchNorm(params)\n",
    "        self.layers['Active3'] = Activation(params)  # relu\n",
    "        self.layers['Affine2'] = Affine(84, params)\n",
    "        self.layers['BatchNorm2'] = BatchNorm(params)\n",
    "        self.layers['Active4'] = Activation(params)  # relu\n",
    "        self.layers['Affine3'] = Affine(params['output_size'], params)\n",
    "\n",
    "    def initialize(self, x, y, params):\n",
    "        in_shape = x.shape \n",
    "        print(x.shape)\n",
    "        out_shape = y.shape \n",
    "        print('###########' * 5)\n",
    "        for i, layer_ in enumerate(self.layers.values()):\n",
    "            print(\" Layer {}\".format(i))\n",
    "            in_shape = layer_.initialize(in_shape, params)\n",
    "            print('###########' * 5)\n",
    "\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y_pred = self.predict(x)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        y_true = np.argmax(t, axis=1)\n",
    "        data_size = x.shape[0]\n",
    "        correct_count = np.sum([y_true == y_pred])\n",
    "        score = correct_count / data_size * 100\n",
    "        return round(score, 2)\n",
    "\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "\n",
    "    \n",
    "    def optimize(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)   \n",
    "        # backward\n",
    "        dout = self.lastLayer.backward(1)\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)    \n",
    "        for layer in self.layers.values():         \n",
    "            if hasattr(layer, \"optimize\"):\n",
    "                layer.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self, init='gauss', epochs=10, lr=0.05, lam=0.01,\n",
    "                 batch_mode='batch', activation='relu',\n",
    "                 batch_size_rate=0.0016, hidden_layer_list=[5], optimizer='sgd',\n",
    "                 batch_norm=False, dropout_ratio=0.0):\n",
    "        \"\"\" ハイパーパラメータ解説\n",
    "        init: 初期化方法\n",
    "            'he' :\n",
    "            'gauss'\n",
    "            'xavier'\n",
    "        lr : 学習率\n",
    "        lam : 正則化項の率\n",
    "        batch_size: バッチサイズ\n",
    "            'batch' : フルサイズ\n",
    "            'mini' 0< x< 1: フルサイズ割合 0.1なら全体の0.1サイズ使用する\n",
    "            'online' : オンライン学習　１データのみ\n",
    "        hidden_layer_list : 隠れ層のリスト、層のユニットをリストで入力　例[2, 3]　ユニット数２、\\\n",
    "　　　　　　　　　　　　　　ユニット数３の隠れ層\n",
    "        optimizer : 勾配の更新手法\n",
    "            'sgd' \n",
    "            'adam'\n",
    "            'adagrad'\n",
    "        activation: 活性化関数の種類\n",
    "            'relu' \n",
    "            'tanh' \n",
    "            'sigmoid'\n",
    "        \"\"\"\n",
    "        self.params = {}\n",
    "        self.params['epochs'] = epochs\n",
    "        self.params['init'] = init\n",
    "        self.params['lr'] = lr\n",
    "        self.params['lam'] = lam  \n",
    "        self.params['batch_mode'] = batch_mode  \n",
    "        self.params['batch_size_rate'] = batch_size_rate  \n",
    "        self.params['hidden_layer_list'] = hidden_layer_list\n",
    "        self.params['optimizer'] = optimizer\n",
    "        self.params['batch_norm'] = batch_norm\n",
    "        self.params['dropout_ratio'] = dropout_ratio\n",
    "        self.params['activation'] = activation\n",
    "\n",
    "    def train(self, X, y, params={}):\n",
    "        # 入力パラメータがあれば更新する\n",
    "        for key in params:\n",
    "            self.params[key] = params[key]\n",
    "\n",
    "        X = X / 255.0\n",
    "\n",
    "        # 訓練とテストデータに分割\n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "        self.params['data_size'] = X_train.shape[0]\n",
    "        self.params['input_size'] = X_train.shape[1]\n",
    "        self.params['output_size'] = y_train.shape[1]\n",
    "\n",
    "        # コストや正答率の学習曲線を引くためのリストを用意\n",
    "        past_train_costs = []\n",
    "        past_test_costs = []\n",
    "        past_train_accuracy = []\n",
    "        past_test_accuracy = []\n",
    "\n",
    "        N, H, W, C = X_train.shape\n",
    "\n",
    "        # バッチサイズの設定\n",
    "        if self.params['batch_mode'] == 'batch':\n",
    "            self.params['batch_size'] = self.params['data_size']\n",
    "        elif self.params['batch_mode'] == 'mini':\n",
    "            self.params['batch_size'] = int(self.params['data_size'] * self.params['batch_size_rate'])\n",
    "        else:\n",
    "            self.params['batch_size'] = 1\n",
    "        # 隠れ層やレイヤーインスタンス生成\n",
    "        # 入力サイズをバッチ分に調整\n",
    "        in_shape = (self.params['batch_size'], H, W, C)\n",
    "        self.params['layer'] = LeNetLayers(self.params)\n",
    "        # 入出力サイズ\n",
    "        self.params['layer'].initialize(X_train[:self.params['batch_size']],\\\n",
    "                                        y_train[:self.params['batch_size']],\\\n",
    "                                        self.params)\n",
    "\n",
    "        iteration = int(X_train.shape[0] / self.params['batch_size'])\n",
    "        choice_list = list(range(X_train.shape[0]))\n",
    "        \n",
    "        for i in range(self.params['epochs']*iteration):\n",
    "            time10 = time.time()\n",
    "            start = i % iteration * self.params['batch_size']\n",
    "            end = start + self.params['batch_size']\n",
    "            X_batch, y_batch = X_train[choice_list[start:end]], y_train[choice_list[start:end]]\n",
    "\n",
    "            # 誤差逆伝播法によって勾配を求め、値を更新  \n",
    "            self.params['layer'].optimize(X_batch, y_batch)\n",
    "            time111 = time.time()\n",
    "            # 1エポックごとに正答率とコストを算出して保存する\n",
    "            if i==0 or (i%iteration is 0):\n",
    "                train_acc = self.params['layer'].accuracy(X_train, y_train)\n",
    "                past_train_accuracy.append(train_acc)\n",
    "                test_acc = self.params['layer'].accuracy(X_test, y_test)\n",
    "                past_test_accuracy.append(test_acc)\n",
    "                train_loss = self.params['layer'].loss(X_train, y_train)\n",
    "                past_train_costs.append(train_loss)\n",
    "                test_loss = self.params['layer'].loss(X_test, y_test)\n",
    "                past_test_costs.append(test_loss)\n",
    "                print(\"epoch:{} train_acc:{}, train_loss:{}, test_acc:{}, test_loss:{}\"\\\n",
    "                      .format(i//iteration, train_acc, train_loss, test_acc, test_loss))\n",
    "            if i%iteration is 9:\n",
    "                random.shuffle(choice_list)\n",
    "        return past_train_accuracy, past_test_accuracy, past_train_costs, past_test_costs\n",
    "\n",
    "\n",
    "    def predict(self, X, probability=False):\n",
    "        predict = self.params['layer'].predict(X, train_flg=False)\n",
    "        predict_proba = softmax(predict)\n",
    "        if probability is True:\n",
    "            return predict_proba\n",
    "        else:\n",
    "            return np.argmax(predict_proba, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/font_manager.py:278: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 32, 3)\n",
      "#######################################################\n",
      " Layer 0\n",
      "Convolution : out (32, 32, 32, 6), filter 5, stride 1 \n",
      "#######################################################\n",
      " Layer 1\n",
      "Activation : out (32, 32, 32, 6)   func : relu \n",
      "#######################################################\n",
      " Layer 2\n",
      "Pooling : out (32, 16, 16, 6) filter 2 stride 2 pad 0 \n",
      "#######################################################\n",
      " Layer 3\n",
      "Convolution : out (32, 16, 16, 16), filter 5, stride 1 \n",
      "#######################################################\n",
      " Layer 4\n",
      "Activation : out (32, 16, 16, 16)   func : relu \n",
      "#######################################################\n",
      " Layer 5\n",
      "Pooling : out (32, 8, 8, 16) filter 2 stride 2 pad 0 \n",
      "#######################################################\n",
      " Layer 6\n",
      "Flatten : out (32, 1024) \n",
      "#######################################################\n",
      " Layer 7\n",
      "Affine : out (32, 120) optimizer adam unit 120 \n",
      "#######################################################\n",
      " Layer 8\n",
      "BatchNorm : out (32, 120) lr 0.01  \n",
      "#######################################################\n",
      " Layer 9\n",
      "Activation : out (32, 120)   func : relu \n",
      "#######################################################\n",
      " Layer 10\n",
      "Affine : out (32, 84) optimizer adam unit 84 \n",
      "#######################################################\n",
      " Layer 11\n",
      "BatchNorm : out (32, 84) lr 0.01  \n",
      "#######################################################\n",
      " Layer 12\n",
      "Activation : out (32, 84)   func : relu \n",
      "#######################################################\n",
      " Layer 13\n",
      "Affine : out (32, 10) optimizer adam unit 10 \n",
      "#######################################################\n",
      "epoch:0 train_acc:11.7, train_loss:14.445839959209119, test_acc:11.72, test_loss:14.441785362186058\n",
      "epoch:1 train_acc:52.54, train_loss:10.076294412553665, test_acc:48.18, test_loss:10.471913221915608\n",
      "epoch:2 train_acc:60.73, train_loss:8.978200180279755, test_acc:51.98, test_loss:9.771349353352443\n",
      "epoch:3 train_acc:65.11, train_loss:8.178902243878916, test_acc:52.12, test_loss:9.396924425489289\n",
      "epoch:4 train_acc:68.52, train_loss:7.660551652428033, test_acc:51.9, test_loss:9.293534313169545\n",
      "epoch:5 train_acc:71.08, train_loss:7.144704146416769, test_acc:53.18, test_loss:9.048857947421387\n",
      "epoch:6 train_acc:74.37, train_loss:6.503043020236704, test_acc:53.12, test_loss:8.832030202663447\n",
      "epoch:7 train_acc:76.03, train_loss:6.216567597702711, test_acc:52.64, test_loss:8.827740482613525\n",
      "epoch:8 train_acc:77.56, train_loss:6.032890714355391, test_acc:52.46, test_loss:8.84648996070376\n",
      "epoch:9 train_acc:78.14, train_loss:5.844980824018786, test_acc:51.94, test_loss:8.854275605762707\n",
      "last train cost is 5.844980824018786\n",
      "last test cost is 8.854275605762707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'iteration[epoch]')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "model = CNN(epochs=10, optimizer='adam',batch_norm=True)\n",
    "\n",
    "params = {'batch_mode' : 'mini',\n",
    "          'lr': 0.01}\n",
    "\n",
    "past_train_accuracy, past_test_accuracy, past_train_costs, past_test_costs = model.train(x_train_cifar10,\\\n",
    "                                                                                         y_train_cifar10.\\\n",
    "                                                                                         reshape(image_num, 10),\\\n",
    "                                                                                         params)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(past_train_costs, color='orange', label='train')\n",
    "plt.plot(past_test_costs, color='lime', label='test')\n",
    "plt.ylabel(\"cost\", fontsize=15)\n",
    "print(\"last train cost is {}\".format(past_train_costs[-1]))\n",
    "print(\"last test cost is {}\".format(past_test_costs[-1]))\n",
    "plt.legend()\n",
    "plt.title('Learning Curve', fontsize=20)\n",
    "plt.xlabel(\"iteration[epoch]\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last train accuracy is 78.14\n",
      "last test accuracy is 51.94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'iteration[epoch]')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "#plt.plot(np.array(past_train_accuracy), color='r')\n",
    "plt.plot(past_train_accuracy, color='orange', label='train')\n",
    "plt.plot(past_test_accuracy, color='lime', label='test')\n",
    "plt.ylabel(\"accuracy\", fontsize=15)\n",
    "print(\"last train accuracy is {}\".format(past_train_accuracy[-1]))\n",
    "print(\"last test accuracy is {}\".format(past_test_accuracy[-1]))\n",
    "plt.ylim(-0.5, 100.5)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Learning Curve', fontsize=20)\n",
    "plt.xlabel(\"iteration[epoch]\", fontsize=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
